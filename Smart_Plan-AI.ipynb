{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8251784,"sourceType":"datasetVersion","datasetId":4896319}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\n\nimport os\nimport pathlib\nimport time\nimport datetime\n\nfrom matplotlib import pyplot as plt\nfrom IPython import display","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:39:49.175135Z","iopub.execute_input":"2024-04-28T23:39:49.175883Z","iopub.status.idle":"2024-04-28T23:39:49.181445Z","shell.execute_reply.started":"2024-04-28T23:39:49.175846Z","shell.execute_reply":"2024-04-28T23:39:49.180317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gpus = tf.config.experimental.list_physical_devices('GPU')\nfor gpu in gpus:\n    print(\"Name:\", gpu.name, \"  Type:\", gpu.device_type)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:58:59.473029Z","iopub.execute_input":"2024-04-28T23:58:59.473859Z","iopub.status.idle":"2024-04-28T23:58:59.480179Z","shell.execute_reply.started":"2024-04-28T23:58:59.473821Z","shell.execute_reply":"2024-04-28T23:58:59.479002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.python.client import device_lib\n\ndevice_lib.list_local_devices()","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:59:11.850590Z","iopub.execute_input":"2024-04-28T23:59:11.851073Z","iopub.status.idle":"2024-04-28T23:59:11.863784Z","shell.execute_reply.started":"2024-04-28T23:59:11.851038Z","shell.execute_reply":"2024-04-28T23:59:11.862586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.test.is_gpu_available()","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:59:40.511099Z","iopub.execute_input":"2024-04-28T23:59:40.511869Z","iopub.status.idle":"2024-04-28T23:59:40.520264Z","shell.execute_reply.started":"2024-04-28T23:59:40.511831Z","shell.execute_reply":"2024-04-28T23:59:40.519255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport os\nimport shutil\nimport cv2\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:39:49.186384Z","iopub.execute_input":"2024-04-28T23:39:49.186720Z","iopub.status.idle":"2024-04-28T23:39:50.209159Z","shell.execute_reply.started":"2024-04-28T23:39:49.186691Z","shell.execute_reply":"2024-04-28T23:39:50.208251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\"\"\"\n# Load the two images\nimage1 = cv2.imread(\"/kaggle/working/train/colors/00010218.png\")\nimage2 = cv2.imread(\"/kaggle/working/train/footprints/00010218.png\")\n\n# Ensure both images are of the same size\nif image1.shape != image2.shape:\n    image2 = cv2.resize(image2, (image1.shape[1], image1.shape[0]))  # Resize image2 to match image1's size\n\n# Concatenate the images horizontally\nconcatenated_image = np.concatenate((image1, image2), axis=1)\n\n\n# To save the concatenated image\ncv2.imwrite(\"/kaggle/working/try.png\", concatenated_image)\n\n#/kaggle/working/train/colors/00010218.png\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:39:50.210913Z","iopub.execute_input":"2024-04-28T23:39:50.211279Z","iopub.status.idle":"2024-04-28T23:39:50.667375Z","shell.execute_reply.started":"2024-04-28T23:39:50.211247Z","shell.execute_reply":"2024-04-28T23:39:50.662373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Define paths to the two folders containing images\nfolder1_path = \"/kaggle/input/deconstructed-floor-plan/colors\"\nfolder2_path = \"/kaggle/input/deconstructed-floor-plan/footprints\"\noutput_folder_path = \"/kaggle/working/main\"\n\n# Ensure the output folder exists\nos.makedirs(output_folder_path, exist_ok=True)\n\n# Iterate over the images in folder1 and concatenate with corresponding images in folder2\nfor filename in os.listdir(folder1_path):\n    if os.path.isfile(os.path.join(folder1_path, filename)):\n        img1 = cv2.imread(os.path.join(folder1_path, filename))\n        img2 = cv2.imread(os.path.join(folder2_path, filename))\n\n        # Ensure both images are of the same size\n        if img1.shape != img2.shape:\n            img2 = cv2.resize(img2, (img1.shape[1], img1.shape[0]))\n\n        # Concatenate the images horizontally\n        concatenated_img = np.concatenate((img1, img2), axis=1)\n\n        # Save the concatenated image to the output folder\n        cv2.imwrite(os.path.join(output_folder_path, filename), concatenated_img)\n\nprint(\"Concatenation completed.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:40:33.475919Z","iopub.execute_input":"2024-04-28T23:40:33.476370Z","iopub.status.idle":"2024-04-28T23:45:53.504250Z","shell.execute_reply.started":"2024-04-28T23:40:33.476334Z","shell.execute_reply":"2024-04-28T23:45:53.503131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For deleting unecessary folders","metadata":{}},{"cell_type":"code","source":"\"\"\"\nimport shutil\n\ndef delete_directory(directory):\n    shutil.rmtree(directory)\n    print(f\"Deleted directory: {directory}\")\n\n# Specify the directory you want to delete\ndirectory_to_delete = \"/kaggle/working/footprints\"\n\n# Call the function to delete the specified directory\ndelete_directory(directory_to_delete)\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:39:50.670047Z","iopub.status.idle":"2024-04-28T23:39:50.670450Z","shell.execute_reply.started":"2024-04-28T23:39:50.670268Z","shell.execute_reply":"2024-04-28T23:39:50.670284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n\n# Define paths to the concatenated images folder and output directories for train, test, and validation sets\nconcatenated_folder_path = \"/kaggle/working/main\"\ntrain_path = \"/kaggle/working/train\"\ntest_path = \"/kaggle/working/test\"\nval_path = \"/kaggle/working/val\"\n\n# Ensure the output directories exist\nos.makedirs(train_path, exist_ok=True)\nos.makedirs(test_path, exist_ok=True)\nos.makedirs(val_path, exist_ok=True)\n\n# Load the list of concatenated image filenames\nconcatenated_images = os.listdir(concatenated_folder_path)\n\n# Split the concatenated images into train, test, and validation sets\ntrain_images, test_val_images = train_test_split(concatenated_images, test_size=0.2, random_state=42)\ntest_images, val_images = train_test_split(test_val_images, test_size=0.5, random_state=42)\n\n# Move images to respective directories\ndef move_images(images, src_folder, dst_folder):\n    for img_filename in images:\n        src = os.path.join(src_folder, img_filename)\n        dst = os.path.join(dst_folder, img_filename)\n        shutil.move(src, dst)\n\nmove_images(train_images, concatenated_folder_path, train_path)\nmove_images(test_images, concatenated_folder_path, test_path)\nmove_images(val_images, concatenated_folder_path, val_path)\n\nprint(\"Splitting completed.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:46:38.876981Z","iopub.execute_input":"2024-04-28T23:46:38.877473Z","iopub.status.idle":"2024-04-28T23:46:39.590724Z","shell.execute_reply.started":"2024-04-28T23:46:38.877438Z","shell.execute_reply":"2024-04-28T23:46:39.589666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Checking data","metadata":{}},{"cell_type":"code","source":"\"\"\"\nsample_image1 = tf.io.read_file('/kaggle/working/val/00004140.png')\nsample_image1 = tf.io.decode_png(sample_image1)\nprint(sample_image1.shape)\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:48:07.956848Z","iopub.execute_input":"2024-04-28T23:48:07.957697Z","iopub.status.idle":"2024-04-28T23:48:07.972925Z","shell.execute_reply.started":"2024-04-28T23:48:07.957657Z","shell.execute_reply":"2024-04-28T23:48:07.971754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nplt.figure()\n\nplt.imshow(sample_image1)\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:48:11.694459Z","iopub.execute_input":"2024-04-28T23:48:11.694901Z","iopub.status.idle":"2024-04-28T23:48:12.131133Z","shell.execute_reply.started":"2024-04-28T23:48:11.694866Z","shell.execute_reply":"2024-04-28T23:48:12.129864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nPATH = pathlib.Path('/kaggle/working/')","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:48:15.190886Z","iopub.execute_input":"2024-04-28T23:48:15.191308Z","iopub.status.idle":"2024-04-28T23:48:15.196580Z","shell.execute_reply.started":"2024-04-28T23:48:15.191274Z","shell.execute_reply":"2024-04-28T23:48:15.195416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load(image_file):\n  # Read and decode an image file to a uint8 tensor\n  image = tf.io.read_file(image_file)\n  image = tf.io.decode_jpeg(image)\n\n  # Split each image tensor into two tensors:\n  # - one with a real building facade image\n  # - one with an architecture label image \n  w = tf.shape(image)[1]\n  w = w // 2\n  input_image = image[:, w:, :]\n  real_image = image[:, :w, :]\n\n  # Convert both images to float32 tensors\n  input_image = tf.cast(input_image, tf.float32)\n  real_image = tf.cast(real_image, tf.float32)\n\n  return input_image, real_image","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:48:17.358428Z","iopub.execute_input":"2024-04-28T23:48:17.359321Z","iopub.status.idle":"2024-04-28T23:48:17.366313Z","shell.execute_reply.started":"2024-04-28T23:48:17.359278Z","shell.execute_reply":"2024-04-28T23:48:17.365113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_f, img_c = load(str(PATH / 'train/00002391.png'))\n# Casting to int for matplotlib to display the images\nplt.figure()\nplt.imshow(img_f / 255.0)\nplt.figure()\nplt.imshow(img_c / 255.0)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:48:19.861308Z","iopub.execute_input":"2024-04-28T23:48:19.862027Z","iopub.status.idle":"2024-04-28T23:48:20.677276Z","shell.execute_reply.started":"2024-04-28T23:48:19.861993Z","shell.execute_reply":"2024-04-28T23:48:20.676202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nimg_c = tf.io.read_file('/kaggle/working/test/colors/00005917.png')\nimage_c = tf.io.decode_png(img_c)\ncolor_image = tf.cast(image_c, tf.float32)\n\nimg_f = tf.io.read_file('/kaggle/working/test/footprints/00005917.png')\nimage_f = tf.io.decode_png(img_f)\nfootprints_image = tf.cast(image_f, tf.float32)\n\nimg_w = tf.io.read_file('/kaggle/working/test/walls/00005917.png')\nimage_w = tf.io.decode_png(img_w)\nwalls_image = tf.cast(image_w, tf.float32)\n# Casting to int for matplotlib to display the images\nplt.figure()\nplt.imshow(color_image / 255.0)\nplt.figure()\nplt.imshow(footprints_image / 255.0)\nplt.figure()\nplt.imshow(walls_image / 255.0)\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:48:23.783097Z","iopub.execute_input":"2024-04-28T23:48:23.783922Z","iopub.status.idle":"2024-04-28T23:48:23.792953Z","shell.execute_reply.started":"2024-04-28T23:48:23.783885Z","shell.execute_reply":"2024-04-28T23:48:23.791813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The facade training set consist of 400 images\nBUFFER_SIZE = 500\n# The batch size of 1 produced better results for the U-Net in the original pix2pix experiment\nBATCH_SIZE = 1\n# Each image is 256x256 in size\nIMG_WIDTH = 512\nIMG_HEIGHT = 512","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:53:44.900548Z","iopub.execute_input":"2024-04-28T23:53:44.901500Z","iopub.status.idle":"2024-04-28T23:53:44.906416Z","shell.execute_reply.started":"2024-04-28T23:53:44.901463Z","shell.execute_reply":"2024-04-28T23:53:44.905429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"input_image = img_f\nreal_image = img_c","metadata":{}},{"cell_type":"code","source":"def resize(input_image, real_image, height, width):\n  input_image = tf.image.resize(input_image, [height, width],\n                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n  real_image = tf.image.resize(real_image, [height, width],\n                               method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n\n  return input_image, real_image","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:53:48.044024Z","iopub.execute_input":"2024-04-28T23:53:48.045042Z","iopub.status.idle":"2024-04-28T23:53:48.051148Z","shell.execute_reply.started":"2024-04-28T23:53:48.044985Z","shell.execute_reply":"2024-04-28T23:53:48.050021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def random_crop(input_image, real_image):\n  stacked_image = tf.stack([input_image, real_image], axis=0)\n  cropped_image = tf.image.random_crop(\n      stacked_image, size=[2, IMG_HEIGHT, IMG_WIDTH, 3])\n\n  return cropped_image[0], cropped_image[1]","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:53:50.273345Z","iopub.execute_input":"2024-04-28T23:53:50.273740Z","iopub.status.idle":"2024-04-28T23:53:50.279837Z","shell.execute_reply.started":"2024-04-28T23:53:50.273712Z","shell.execute_reply":"2024-04-28T23:53:50.278720Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Normalizing the images to [-1, 1]\ndef normalize(input_image, real_image):\n  input_image = (input_image / 127.5) - 1\n  real_image = (real_image / 127.5) - 1\n\n  return input_image, real_image","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:53:56.270817Z","iopub.execute_input":"2024-04-28T23:53:56.271269Z","iopub.status.idle":"2024-04-28T23:53:56.276993Z","shell.execute_reply.started":"2024-04-28T23:53:56.271231Z","shell.execute_reply":"2024-04-28T23:53:56.275804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@tf.function()\ndef random_jitter(input_image, real_image):\n  # Resizing to 286x286\n  input_image, real_image = resize(input_image, real_image, 512, 512)\n\n  # Random cropping back to 256x256\n  input_image, real_image = random_crop(input_image, real_image)\n\n  if tf.random.uniform(()) > 0.5:\n    # Random mirroring\n    input_image = tf.image.flip_left_right(input_image)\n    real_image = tf.image.flip_left_right(real_image)\n\n  return input_image, real_image","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:53:58.085819Z","iopub.execute_input":"2024-04-28T23:53:58.086789Z","iopub.status.idle":"2024-04-28T23:53:58.094528Z","shell.execute_reply.started":"2024-04-28T23:53:58.086742Z","shell.execute_reply":"2024-04-28T23:53:58.093440Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(6, 6))\nfor i in range(4):\n  rj_i, rj_r = random_jitter(img_f, img_c)\n  plt.subplot(2, 2, i + 1)\n  plt.imshow(rj_i / 255.0)\n  plt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:54:00.576896Z","iopub.execute_input":"2024-04-28T23:54:00.577455Z","iopub.status.idle":"2024-04-28T23:54:01.223105Z","shell.execute_reply.started":"2024-04-28T23:54:00.577420Z","shell.execute_reply":"2024-04-28T23:54:01.221920Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_image_train(image_file):\n  input_image, real_image = load(image_file)\n  input_image, real_image = random_jitter(input_image, real_image)\n  input_image, real_image = normalize(input_image, real_image)\n\n  return input_image, real_image","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:54:03.383713Z","iopub.execute_input":"2024-04-28T23:54:03.384487Z","iopub.status.idle":"2024-04-28T23:54:03.389914Z","shell.execute_reply.started":"2024-04-28T23:54:03.384446Z","shell.execute_reply":"2024-04-28T23:54:03.388860Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"def load_image_test(image_file):\n  input_image, real_image = load(image_file)\n  input_image, real_image = resize(input_image, real_image,\n                                   IMG_HEIGHT, IMG_WIDTH)\n  input_image, real_image = normalize(input_image, real_image)\n\n  return input_image, real_image","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:54:05.862442Z","iopub.execute_input":"2024-04-28T23:54:05.863477Z","iopub.status.idle":"2024-04-28T23:54:05.869125Z","shell.execute_reply.started":"2024-04-28T23:54:05.863438Z","shell.execute_reply":"2024-04-28T23:54:05.867968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = tf.data.Dataset.list_files(str(PATH / 'train/*.png'))\ntrain_dataset = train_dataset.map(load_image_train,\n                                  num_parallel_calls=tf.data.AUTOTUNE)\ntrain_dataset = train_dataset.shuffle(BUFFER_SIZE)\ntrain_dataset = train_dataset.batch(BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:54:07.601625Z","iopub.execute_input":"2024-04-28T23:54:07.602042Z","iopub.status.idle":"2024-04-28T23:54:07.844648Z","shell.execute_reply.started":"2024-04-28T23:54:07.602010Z","shell.execute_reply":"2024-04-28T23:54:07.843665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n  test_dataset = tf.data.Dataset.list_files(str(PATH / 'test/*.png'))\nexcept tf.errors.InvalidArgumentError:\n  test_dataset = tf.data.Dataset.list_files(str(PATH / 'val/*.png'))\ntest_dataset = test_dataset.map(load_image_test)\ntest_dataset = test_dataset.batch(BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:54:09.661079Z","iopub.execute_input":"2024-04-28T23:54:09.661832Z","iopub.status.idle":"2024-04-28T23:54:09.782364Z","shell.execute_reply.started":"2024-04-28T23:54:09.661798Z","shell.execute_reply":"2024-04-28T23:54:09.781416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Building a generator","metadata":{}},{"cell_type":"code","source":"OUTPUT_CHANNELS = 3","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:54:12.426511Z","iopub.execute_input":"2024-04-28T23:54:12.427556Z","iopub.status.idle":"2024-04-28T23:54:12.432299Z","shell.execute_reply.started":"2024-04-28T23:54:12.427514Z","shell.execute_reply":"2024-04-28T23:54:12.431015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def downsample(filters, size, apply_batchnorm=True):\n  initializer = tf.random_normal_initializer(0., 0.02)\n\n  result = tf.keras.Sequential()\n  result.add(\n      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n                             kernel_initializer=initializer, use_bias=False))\n\n  if apply_batchnorm:\n    result.add(tf.keras.layers.BatchNormalization())\n\n  result.add(tf.keras.layers.LeakyReLU())\n\n  return result","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:54:15.101862Z","iopub.execute_input":"2024-04-28T23:54:15.102626Z","iopub.status.idle":"2024-04-28T23:54:15.109514Z","shell.execute_reply.started":"2024-04-28T23:54:15.102588Z","shell.execute_reply":"2024-04-28T23:54:15.108243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"down_model = downsample(3, 4)\ndown_result = down_model(tf.expand_dims(img_f, 0))\nprint (down_result.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:54:17.105045Z","iopub.execute_input":"2024-04-28T23:54:17.105511Z","iopub.status.idle":"2024-04-28T23:54:17.140448Z","shell.execute_reply.started":"2024-04-28T23:54:17.105477Z","shell.execute_reply":"2024-04-28T23:54:17.139145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def upsample(filters, size, apply_dropout=False):\n  initializer = tf.random_normal_initializer(0., 0.02)\n\n  result = tf.keras.Sequential()\n  result.add(\n    tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n                                    padding='same',\n                                    kernel_initializer=initializer,\n                                    use_bias=False))\n\n  result.add(tf.keras.layers.BatchNormalization())\n\n  if apply_dropout:\n      result.add(tf.keras.layers.Dropout(0.5))\n\n  result.add(tf.keras.layers.ReLU())\n\n  return result","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:54:20.203772Z","iopub.execute_input":"2024-04-28T23:54:20.204180Z","iopub.status.idle":"2024-04-28T23:54:20.212124Z","shell.execute_reply.started":"2024-04-28T23:54:20.204150Z","shell.execute_reply":"2024-04-28T23:54:20.210725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"up_model = upsample(3, 4)\nup_result = up_model(down_result)\nprint (up_result.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:54:22.580550Z","iopub.execute_input":"2024-04-28T23:54:22.580973Z","iopub.status.idle":"2024-04-28T23:54:22.613344Z","shell.execute_reply.started":"2024-04-28T23:54:22.580942Z","shell.execute_reply":"2024-04-28T23:54:22.612244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Generator():\n  inputs = tf.keras.layers.Input(shape=[512, 512, 3])\n\n  down_stack = [\n    downsample(128, 4, apply_batchnorm=False),  # (batch_size, 128, 128, 64)\n    downsample(256, 4),  # (batch_size, 64, 64, 128)\n    downsample(512, 4),  # (batch_size, 32, 32, 256)\n    downsample(1024, 4),  # (batch_size, 16, 16, 512)\n    downsample(1024, 4),  # (batch_size, 8, 8, 512)\n    downsample(1024, 4),  # (batch_size, 4, 4, 512)\n    downsample(1024, 4),  # (batch_size, 2, 2, 512)\n    downsample(1024, 4),  # (batch_size, 1, 1, 512)\n  ]\n\n  up_stack = [\n    upsample(1024, 4, apply_dropout=True),  # (batch_size, 2, 2, 1024)\n    upsample(1024, 4, apply_dropout=True),  # (batch_size, 4, 4, 1024)\n    upsample(1024, 4, apply_dropout=True),  # (batch_size, 8, 8, 1024)\n    upsample(1024, 4),  # (batch_size, 16, 16, 1024)\n    upsample(512, 4),  # (batch_size, 32, 32, 512)\n    upsample(256, 4),  # (batch_size, 64, 64, 256)\n    upsample(128, 4),  # (batch_size, 128, 128, 128)\n  ]\n\n  initializer = tf.random_normal_initializer(0., 0.02)\n  last = tf.keras.layers.Conv2DTranspose(OUTPUT_CHANNELS, 4,\n                                         strides=2,\n                                         padding='same',\n                                         kernel_initializer=initializer,\n                                         activation='tanh')  # (batch_size, 256, 256, 3)\n\n  x = inputs\n\n  # Downsampling through the model\n  skips = []\n  for down in down_stack:\n    x = down(x)\n    skips.append(x)\n\n  skips = reversed(skips[:-1])\n\n  # Upsampling and establishing the skip connections\n  for up, skip in zip(up_stack, skips):\n    x = up(x)\n    x = tf.keras.layers.Concatenate()([x, skip])\n\n  x = last(x)\n\n  return tf.keras.Model(inputs=inputs, outputs=x)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:54:25.639350Z","iopub.execute_input":"2024-04-28T23:54:25.640167Z","iopub.status.idle":"2024-04-28T23:54:25.652308Z","shell.execute_reply.started":"2024-04-28T23:54:25.640133Z","shell.execute_reply":"2024-04-28T23:54:25.651030Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\ngenerator = Generator()\ntf.keras.utils.plot_model(generator, show_shapes=True, dpi=64)\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:39:50.717822Z","iopub.status.idle":"2024-04-28T23:39:50.718173Z","shell.execute_reply.started":"2024-04-28T23:39:50.717999Z","shell.execute_reply":"2024-04-28T23:39:50.718014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator=Generator()\ngen_output = generator(img_f[tf.newaxis, ...], training=False)\nplt.imshow(gen_output[0, ...])","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:54:28.660949Z","iopub.execute_input":"2024-04-28T23:54:28.662487Z","iopub.status.idle":"2024-04-28T23:54:29.376357Z","shell.execute_reply.started":"2024-04-28T23:54:28.662434Z","shell.execute_reply":"2024-04-28T23:54:29.375219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LAMBDA = 100","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:49:42.314831Z","iopub.execute_input":"2024-04-28T23:49:42.315566Z","iopub.status.idle":"2024-04-28T23:49:42.320322Z","shell.execute_reply.started":"2024-04-28T23:49:42.315526Z","shell.execute_reply":"2024-04-28T23:49:42.319085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:54:39.075330Z","iopub.execute_input":"2024-04-28T23:54:39.075780Z","iopub.status.idle":"2024-04-28T23:54:39.081145Z","shell.execute_reply.started":"2024-04-28T23:54:39.075740Z","shell.execute_reply":"2024-04-28T23:54:39.079921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generator_loss(disc_generated_output, gen_output, target):\n  gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n\n  # Mean absolute error\n  l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n\n  total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n\n  return total_gen_loss, gan_loss, l1_loss","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:54:41.102107Z","iopub.execute_input":"2024-04-28T23:54:41.102930Z","iopub.status.idle":"2024-04-28T23:54:41.109394Z","shell.execute_reply.started":"2024-04-28T23:54:41.102888Z","shell.execute_reply":"2024-04-28T23:54:41.108170Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Discriminator","metadata":{}},{"cell_type":"code","source":"def Discriminator():\n  initializer = tf.random_normal_initializer(0., 0.02)\n\n  inp = tf.keras.layers.Input(shape=[512, 512, 3], name='input_image')\n  tar = tf.keras.layers.Input(shape=[512, 512, 3], name='target_image')\n\n  x = tf.keras.layers.concatenate([inp, tar])  # (batch_size, 256, 256, channels*2)\n\n  down1 = downsample(128, 4, False)(x)  # (batch_size, 128, 128, 64)\n  down2 = downsample(256, 4)(down1)  # (batch_size, 64, 64, 128)\n  down3 = downsample(512, 4)(down2)  # (batch_size, 32, 32, 256)\n\n  zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3)  # (batch_size, 34, 34, 256)\n  conv = tf.keras.layers.Conv2D(1024, 4, strides=1,\n                                kernel_initializer=initializer,\n                                use_bias=False)(zero_pad1)  # (batch_size, 31, 31, 512)\n\n  batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n\n  leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n\n  zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)  # (batch_size, 33, 33, 512)\n\n  last = tf.keras.layers.Conv2D(1, 4, strides=1,\n                                kernel_initializer=initializer)(zero_pad2)  # (batch_size, 30, 30, 1)\n\n  return tf.keras.Model(inputs=[inp, tar], outputs=last)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:54:43.368670Z","iopub.execute_input":"2024-04-28T23:54:43.369120Z","iopub.status.idle":"2024-04-28T23:54:43.380879Z","shell.execute_reply.started":"2024-04-28T23:54:43.369082Z","shell.execute_reply":"2024-04-28T23:54:43.379774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discriminator = Discriminator()\ndisc_out = discriminator([img_f[tf.newaxis, ...], gen_output], training=False)\nplt.imshow(disc_out[0, ..., -1], vmin=-20, vmax=20, cmap='RdBu_r')\nplt.colorbar()","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:54:45.971397Z","iopub.execute_input":"2024-04-28T23:54:45.972400Z","iopub.status.idle":"2024-04-28T23:54:46.447815Z","shell.execute_reply.started":"2024-04-28T23:54:45.972365Z","shell.execute_reply":"2024-04-28T23:54:46.446857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def discriminator_loss(disc_real_output, disc_generated_output):\n  real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n\n  generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n\n  total_disc_loss = real_loss + generated_loss\n\n  return total_disc_loss","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:54:49.218399Z","iopub.execute_input":"2024-04-28T23:54:49.219117Z","iopub.status.idle":"2024-04-28T23:54:49.225086Z","shell.execute_reply.started":"2024-04-28T23:54:49.219080Z","shell.execute_reply":"2024-04-28T23:54:49.224069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:54:51.684007Z","iopub.execute_input":"2024-04-28T23:54:51.685122Z","iopub.status.idle":"2024-04-28T23:54:51.696055Z","shell.execute_reply.started":"2024-04-28T23:54:51.685079Z","shell.execute_reply":"2024-04-28T23:54:51.695004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_dir = './training_checkpoints'\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\ncheckpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n                                 discriminator_optimizer=discriminator_optimizer,\n                                 generator=generator,\n                                 discriminator=discriminator)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:54:53.524353Z","iopub.execute_input":"2024-04-28T23:54:53.524778Z","iopub.status.idle":"2024-04-28T23:54:53.531667Z","shell.execute_reply.started":"2024-04-28T23:54:53.524741Z","shell.execute_reply":"2024-04-28T23:54:53.530498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_images(model, test_input, tar):\n  prediction = model(test_input, training=True)\n  plt.figure(figsize=(15, 15))\n\n  display_list = [test_input[0], tar[0], prediction[0]]\n  title = ['Input Image', 'Ground Truth', 'Predicted Image']\n\n  for i in range(3):\n    plt.subplot(1, 3, i+1)\n    plt.title(title[i])\n    # Getting the pixel values in the [0, 1] range to plot.\n    plt.imshow(display_list[i] * 0.5 + 0.5)\n    plt.axis('off')\n  plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:54:55.593222Z","iopub.execute_input":"2024-04-28T23:54:55.593645Z","iopub.status.idle":"2024-04-28T23:54:55.601814Z","shell.execute_reply.started":"2024-04-28T23:54:55.593610Z","shell.execute_reply":"2024-04-28T23:54:55.600505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for example_input, example_target in test_dataset.take(1):\n  generate_images(generator, example_input, example_target)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:54:58.237132Z","iopub.execute_input":"2024-04-28T23:54:58.237607Z","iopub.status.idle":"2024-04-28T23:54:59.049009Z","shell.execute_reply.started":"2024-04-28T23:54:58.237570Z","shell.execute_reply":"2024-04-28T23:54:59.047885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"log_dir=\"logs/\"\n\nsummary_writer = tf.summary.create_file_writer(\n  log_dir + \"fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:55:02.180967Z","iopub.execute_input":"2024-04-28T23:55:02.181420Z","iopub.status.idle":"2024-04-28T23:55:02.189933Z","shell.execute_reply.started":"2024-04-28T23:55:02.181381Z","shell.execute_reply":"2024-04-28T23:55:02.188696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef train_step(input_image, target, step):\n  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n    gen_output = generator(input_image, training=True)\n\n    disc_real_output = discriminator([input_image, target], training=True)\n    disc_generated_output = discriminator([input_image, gen_output], training=True)\n\n    gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output, gen_output, target)\n    disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n\n  generator_gradients = gen_tape.gradient(gen_total_loss,\n                                          generator.trainable_variables)\n  discriminator_gradients = disc_tape.gradient(disc_loss,\n                                               discriminator.trainable_variables)\n\n  generator_optimizer.apply_gradients(zip(generator_gradients,\n                                          generator.trainable_variables))\n  discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\n                                              discriminator.trainable_variables))\n\n  with summary_writer.as_default():\n    tf.summary.scalar('gen_total_loss', gen_total_loss, step=step//1000)\n    tf.summary.scalar('gen_gan_loss', gen_gan_loss, step=step//1000)\n    tf.summary.scalar('gen_l1_loss', gen_l1_loss, step=step//1000)\n    tf.summary.scalar('disc_loss', disc_loss, step=step//1000)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T00:00:37.539560Z","iopub.execute_input":"2024-04-29T00:00:37.540833Z","iopub.status.idle":"2024-04-29T00:00:37.552173Z","shell.execute_reply.started":"2024-04-29T00:00:37.540783Z","shell.execute_reply":"2024-04-29T00:00:37.550989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit(train_ds, test_ds, steps):\n  example_input, example_target = next(iter(test_ds.take(1)))\n  start = time.time()\n\n  for step, (input_image, target) in train_ds.repeat().take(steps).enumerate():\n    if (step) % 1000 == 0:\n      display.clear_output(wait=True)\n\n      if step != 0:\n        print(f'Time taken for 1000 steps: {time.time()-start:.2f} sec\\n')\n\n      start = time.time()\n\n      generate_images(generator, example_input, example_target)\n      print(f\"Step: {step//1000}k\")\n\n    train_step(input_image, target, step)\n\n    # Training step\n    if (step+1) % 10 == 0:\n      print('.', end='', flush=True)\n\n\n    # Save (checkpoint) the model every 5k steps\n    if (step + 1) % 5000 == 0:\n      checkpoint.save(file_prefix=checkpoint_prefix)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T00:03:31.756317Z","iopub.execute_input":"2024-04-29T00:03:31.757174Z","iopub.status.idle":"2024-04-29T00:03:31.767231Z","shell.execute_reply.started":"2024-04-29T00:03:31.757133Z","shell.execute_reply":"2024-04-29T00:03:31.766018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\n%load_ext tensorboard\n%tensorboard --logdir {log_dir}\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:39:50.744068Z","iopub.status.idle":"2024-04-28T23:39:50.744493Z","shell.execute_reply.started":"2024-04-28T23:39:50.744308Z","shell.execute_reply":"2024-04-28T23:39:50.744324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device_name = tf.test.gpu_device_name()\n\nif \"GPU\" not in device_name:\n    print(\"GPU device not found\")\n    \nprint('Found GPU at: {}'.format(device_name))\n\nprint(\"GPU\", \"available (YESS!!!!)\" if tf.config.list_physical_devices(\"GPU\") else \"not available :(\")","metadata":{"execution":{"iopub.status.busy":"2024-04-28T23:55:15.564403Z","iopub.execute_input":"2024-04-28T23:55:15.565156Z","iopub.status.idle":"2024-04-28T23:55:15.573777Z","shell.execute_reply.started":"2024-04-28T23:55:15.565119Z","shell.execute_reply":"2024-04-28T23:55:15.572637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fit(train_dataset, test_dataset, steps=10000)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T00:17:36.011533Z","iopub.execute_input":"2024-04-29T00:17:36.012006Z","iopub.status.idle":"2024-04-29T01:25:46.671065Z","shell.execute_reply.started":"2024-04-29T00:17:36.011970Z","shell.execute_reply":"2024-04-29T01:25:46.669556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\ngenerator.summary()\ndiscriminator.summary()\ngenerator.save('/kaggle/working/gen')\ngenerator.save('/kaggle/working/Gen.h5')\ndiscriminator.save('/kaggle/working/disc')\ndiscriminator.save('/kaggle/working/disc.h5')\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-04-29T01:49:00.409965Z","iopub.execute_input":"2024-04-29T01:49:00.410685Z","iopub.status.idle":"2024-04-29T01:49:00.417200Z","shell.execute_reply.started":"2024-04-29T01:49:00.410645Z","shell.execute_reply":"2024-04-29T01:49:00.416142Z"},"trusted":true},"execution_count":null,"outputs":[]}]}
